from openai import OpenAI
from app.utils.config import OPENAI_API_KEY_MASTERSCHOOL


client = OpenAI(api_key=OPENAI_API_KEY_MASTERSCHOOL)
# ---------- ðŸ§  GPT: Lokale Hilfe & Matches -------------------------------------

def generate_agent_response(
    history: list[dict[str, str]],
    matches: list[dict[str, str]] = [],
    mode: str = "suchen",
    followup: bool = False
) -> str:
    """
    Erstellt eine GPT-Antwort basierend auf Chatverlauf, Matches und Anfrage-Modus.
    Optional: followup=True markiert es als RÃ¼ckfrage.
    """
    user_role = "suchender" if mode == "suchen" else "helfender"

    # ðŸ“Œ Systemprompt
    system_prompt = (
        f"Du bist ein empathischer WhatsApp-Assistent, der Nutzer:innen dabei hilft, Ã¼ber eine Nachbarschafts-App "
        f"Hilfe zu finden oder anzubieten. Achte auf einen freundlichen Ton, Klarheit und max. 3 AbsÃ¤tze. "
        f"Nenne konkrete VorschlÃ¤ge oder stelle RÃ¼ckfragen. Antworte WhatsApp-gerecht, Emoji erlaubt."
    )
    if followup:
        system_prompt += (
            "\nDies ist eine RÃ¼ckfrage in einem laufenden GesprÃ¤ch. Reagiere prÃ¤zise und hilfreich, ohne alles zu wiederholen."
        )

    messages = [{"role": "system", "content": system_prompt}]

    # ðŸ“œ Kontextualisierter Verlauf
    for msg in history:
        role = "user" if msg["direction"] == "inbound" else "assistant"
        messages.append({"role": role, "content": msg["message"].strip()})

    # ðŸ§© Matches strukturiert bereitstellen
    if matches:
        match_text = "\n".join(
            f"ðŸ‘¤ *{m['name']}*: {m['bio'].strip()}" for m in matches
        )
        summary = (
            "Hier sind mÃ¶gliche passende Personen aus der App:\n\n"
            f"{match_text}"
        )
    else:
        summary = "Es wurden keine direkten Personen gefunden, die gut passen."

    messages.append({
        "role": "system",
        "content": f"ZusÃ¤tzliche Info (nicht zeigen, aber nutzen):\n{summary}"
    })

    # ðŸ‘‰ Aufforderung zur Antwort
    messages.append({
        "role": "user",
        "content": "Kannst du mir jetzt bitte helfen oder etwas vorschlagen?"
    })

    # ðŸ’¬ GPT-Antwort
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=400,
    )

    return response.choices[0].message.content.strip()

# ---------- ðŸŒ GPT: Externe Online-Suche -------------------------------------

def generate_online_suggestions(query: str, location: str = "", mode: str = "suchen") -> str:
    """
    Erstellt externe VorschlÃ¤ge basierend auf Anliegen und (optionalem) Standort.
    """
    user_role = "um Hilfe zu erhalten" if mode == "suchen" else "um Hilfe anzubieten"
    location_text = f" in {location}" if location else ""

    prompt = (
        f"Ein Nutzer mÃ¶chte {user_role}. Das Anliegen lautet:\n\n\"{query}\"\n\n"
        f"Der Standort ist{location_text}.\n\n"
        "Erstelle eine WhatsApp-optimierte Antwort mit 2â€“3 konkreten externen Tipps oder Plattformen:\n"
        "- ðŸŽ¯ *Titel (fett)*\n"
        "- 1 kurze ErklÃ¤rung\n"
        "- ðŸ“Ž Weblink \n\n"
        "Antwort max. 3 AbsÃ¤tze. Klar, hilfreich, empathisch. Keine Floskeln."
    )

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Du bist ein Recherche-Assistent fÃ¼r soziale Hilfen."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.8,
        max_tokens=500
    )

    return response.choices[0].message.content.strip()

